## Neural Network Notes

[Initialize Weights Tutorial (Deep Learning.ai)](https://www.deeplearning.ai/ai-notes/initialization/)

[My Network always predict the same class](https://stackoverflow.com/questions/41488279/neural-network-always-predicts-the-same-class)

[Interesting Explanation of how the circles dataset struggles to be separated](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)


> Error using binary cross entropy with sigmoid activation function on the final layer. It causes a division by 0 error as it outputs 0 or 1. Why is this? Some posts solutions:
- [Add a small epsilon to cost function](https://stackoverflow.com/questions/38125319/python-divide-by-zero-encountered-in-log-logistic-regression)
- [Precision implications on crossentropy-based optimization](https://stackoverflow.com/questions/52125924/why-does-sigmoid-crossentropy-of-keras-tensorflow-have-low-precision)
- [Here it's an example of how it is done in scikit-learn](https://github.com/scikit-learn/scikit-learn/blob/fd237278e/sklearn/metrics/_classification.py#L2213)


[Cross Entropy Loss Function Explained](http://neuralnetworksanddeeplearning.com/chap3.html#the_cross-entropy_cost_function)

[Very well developed and mathematically explained notes on neural network implementation](https://peterroelants.github.io/posts/neural-network-implementation-part02/)